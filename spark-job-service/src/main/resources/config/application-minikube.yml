spring:
  redis:
    uri: localhost:6379
logging:
  logback:
    rollingpolicy:
      clean-history-on-start: true
  file:
    path: logs
    name: ${logging.file.path}/application.log
  level:
    ROOT: info
    org.apache.spark: warn
    org.apache.hadoop: warn
    org.sparkproject: warn
debug: false

# ===================================================================
# Application specific properties
# Add your own application properties here
# ===================================================================

#------------------------- Spark configurations -------------------------
spark:
  # Need to change this whenever minikube is restarted. Find using `kubectl cluster-info`
  master: k8s://https://127.0.0.1:54265
#  master: k8s://https://kubernetes.default.svc
  executor:
    instances: 2
    memory: 2g
    cores: 1
  driver:
    memory: 1g
    cores: 1
    extraJavaOptions: >
      -DMONGODB_URL=mongodb://192.168.1.6:27017
      -DSPARK_OUTPUT_PATH=spark-output
  kubernetes:
    namespace: default
    authenticate.driver.serviceAccountName: spark
    driverEnv:
      SPARK_USER: spark
    #Always, Never, and IfNotPresent
  #    container.image.pullPolicy: IfNotPresent
  submit.deployMode: cluster

#------------------------- Spark Submit Job configurations -------------------------
spark-submit:
  capture-jobs-logs: false
  persist-jobs: true
  jobs:
    daily-sales-report-job:
      jar-file: local:///opt/spark/job-apps/spark-batch-daily-sales-report-job.jar
      spark-config:
        spark.kubernetes.namespace: default
        spark.kubernetes.container.image: spark-batch-daily-sales-report-job:0.0.1
        spark.kubernetes.authenticate.driver.serviceAccountName: spark
        spark.kubernetes.driverEnv.SPARK_USER: spark
